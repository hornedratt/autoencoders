{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b568629",
   "metadata": {},
   "source": [
    "# Denoising autoencoder в распозновании масс-спектров MALDI-TOF\n",
    " В данном репозитории представленны методы классификации масс-спектров MALDI-TOF с использованием denoising автоенкодера (далее DAE), для снижения размерности профилей, и модели случайного леса, для классификации скрытых состояний. Также, присутствуют методы зашумления профилей (так как была острая нехватка исходных данных (~ 150 профилей) и, вместе с этим, это необходимо для обучения DAE) и методы анализирующие некоторые характеристики моделей и данных. Все представленные результаты слишком идеальные, так как, как я уже упоминала исходный датасэт был всего 150 профилей, поэтому их не нужно воспринимать как настоящие результаты, скорее это просто пример того что делает данный репозиторий.  \n",
    "\n",
    "### Данные\n",
    " Данные представляют собой вектора размерером 12000, где каждая компонента - нормированная методами от MALDI-TOF интенсивность белка с определенной массой, т. е. это вещественное число из интервала [0, 1], с двумя лейблами - группа и штамм, пример исходных данных есть в data/raw.\n",
    " \n",
    "### Шум\n",
    " Метод add_normal_noise генирирует набор зашумленных профилей для построения модели случайного леса (10 зашумленных из одного оригинального) по формуле:\n",
    "$$C_n = |C_o + \\xi|, \\xi \\in N(0, \\sigma * d)$$\n",
    "где $C_o$ - некоторая кордината оригинального профиля, $\\sigma$ - средне-квадратичное отклонение координат в рассматриваемом оригинальном профиле, d - доля (уровень) шума от оригинального. В предложенном пайплайне $d \\in \\{ 0.1, 0.2, 0.3, 0.4 \\}$. Все $C_n > 1$ заменяются на 1.\n",
    "В автоенкодере зашумление происходит аналогичным образом на этапе формирования батча(по умолчанию размер набора для данных для автоенкодера - 2500 шт. (если ваш набор больше этот параметр нужно будет увеличить, см \"Требования и запуск пайплайна\"), batch_size=64, train_size=0.7) (все последующие примеры графиков и отчетов будут для $d=0.4$)\n",
    "\n",
    "### Pipeline\n",
    "Пайплайн был написан с помощью snakemake, его DAG:\n",
    "![DAG](reports/figures/DAG.png?raw=true)\n",
    "\n",
    "### Обучение DAE\n",
    " Vanilla autoencoder - полносвязный автоенкодер. По умолчанию количество эпох - 50. В методе train строиться график функции потерь от эпохи на train и valid выборках:\n",
    "<img src='reports/figures/DAE_norm_noise_40%.png' width=320>\n",
    " Также, в пайплайне строиться heat map,для разбиения по группам и штаммам, соответственно:\n",
    "<img src='reports/figures/heat_map_group_40%.png' width=420>\n",
    "<img src='reports/figures/heat_map_id_40%.png' width=420>\n",
    " Каждая точка в heatmap - евклидово расстояние между средними групп/штаммов, на диагонали стоят среднегрупповые/среднештаммовые расстояния. Так как строики/столбцы у каждой группы/штамма хорошо различимы и минимальные значения стоят на диагоналях, можно предположить, что полученное скрытое пространство хорошо подходит для дальнейшего решения задачи классификации.\n",
    " \n",
    " ### Обучение случайного леса\n",
    "  Реализация случайного леса была взята из библиотеки scikit-learn cо следующими параметрами: n_estimators=10, criterion='gini', min_samples_split=8, min_samples_leaf=4). Train_forest сохраняет отчет о работе построенного леса (прмиер с группами, со штаммами есть аналогичный отчет):\n",
    "  \n",
    "|                |   precision |   recall |   f1-score |    support |\n",
    "|:----------------------------|------------:|---------:|-----------:|-----------:|\n",
    "| Anoxybacillus_flavithermus  |    1        | 1        |   1        |   8        |\n",
    "| Bacillus_altitudinis        |    1        | 0.985075 |   0.992481 |  67        |\n",
    "| Bacillus_aryabhattai        |    1        | 1        |   1        |   4        |\n",
    "| Bacillus_atrophaeus         |    1        | 1        |   1        |  10        |\n",
    "| Bacillus_berkeleyi          |    1        | 1        |   1        |   7        |\n",
    "| Bacillus_cereus             |    1        | 1        |   1        |  46        |\n",
    "| Bacillus_chungangenis       |    1        | 1        |   1        |   5        |\n",
    "| Bacillus_clausii            |    1        | 1        |   1        |   8        |\n",
    "| Bacillus_coagulans          |    1        | 1        |   1        |   6        |\n",
    "| Bacillus_flexus             |    1        | 1        |   1        |  14        |\n",
    "| Bacillus_licheniformis      |    1        | 1        |   1        |  72        |\n",
    "| Bacillus_megaterium         |    1        | 1        |   1        |  50        |\n",
    "| Bacillus_mycoides           |    1        | 1        |   1        |   3        |\n",
    "| Bacillus_pumilus            |    0.991071 | 1        |   0.995516 | 111        |\n",
    "| Bacillus_simplex            |    1        | 1        |   1        |  40        |\n",
    "| Bacillus_subtilis           |    1        | 1        |   1        |   4        |\n",
    "| Bacillus_thuringiensis      |    1        | 1        |   1        |   5        |\n",
    "| Bacillus_weihenstephanensis |    1        | 1        |   1        |   7        |\n",
    "| E-Coli                      |    1        | 1        |   1        |   7        |\n",
    "| Geobacillus_subterraneus    |    1        | 1        |   1        |  18        |\n",
    "| accuracy                    |    0.997967 | 0.997967 |   0.997967 |   0.997967 |\n",
    "| macro avg                   |    0.999554 | 0.999254 |   0.9994   | 492        |\n",
    "| weighted avg                |    0.997986 | 0.997967 |   0.997964 | 492        |\n",
    "  \n",
    "   Также, в пайплайне строиться гистограмма точностей при кроссвалидации (по умолчанию валидируемся 1000 раз):\n",
    "<img src='reports/figures/cross_valid_40%_result_group.png' width=420>\n",
    " importance analysis, на основании критерия gini строит график наиболее важных для классификации фичей в скрытом состоянии(прмиер с группами, со штаммами есть аналогичный график):\n",
    "<img src='reports/figures/forest_40%_importances_group.png' width=420>\n",
    " после чего по самым большим весам кодера идем до его входного слоя, на котором,через веса $\\omega_{j d}$, ищутся самые важные фичи для классификации уже в исходном пространстве, по формуле:\n",
    " \n",
    "$$\n",
    "\\omega_{j k}^{(1)}-\\operatorname{mean}\\left(\\omega_{j d}^{(1)}\\right)>\\beta * \\operatorname{std}\\left(\\omega_{j d}^{(1)}\\right)\n",
    "$$\n",
    "\n",
    "т. е. согласно этой формуле k-ая фича - является важной. Здесь \\beta - гиперпараметр, который подбирался так, чтобы мы находили ~ 150 важных фичей. Номера этих фичей лежат в reports/mz_features_40%_group.txt\n",
    "### Cross noise\n",
    " Последний метод в пайплайне берет все полученные модели и сэты и строит матрицы с точностями и f1-мерами при применении моделей к сэтам с уровнями шума, отличными от тех, на которых эти модели обучались. Строки отвечают за уровень шума при обучении (Train Noise), а столюцы на уровень шума на входе (Input Noise). Пример с f1-мерой для групп:\n",
    " \n",
    "|   |   | Input Noise        | Input Noise     | Input Noise   | Input Noise    |\n",
    "|:-------------|:-------------|:-------------------|:-------------------|:-------------------|:-------------------|\n",
    "|         |        | 10%                | 20%                | 30%                | 40%                |\n",
    "| Train Noise  | 10%          | 1.0                | 1.0                | 1.0                | 1.0                |\n",
    "| Train Noise  | 20%          | 0.9982857142857142 | 0.9982857142857142 | 0.9982857142857142 | 0.9982857142857142 |\n",
    "| Train Noise  | 30%          | 0.99728002920774   | 0.99728002920774   | 0.99728002920774   | 0.99728002920774   |\n",
    "| Train Noise  | 40%          | 0.9993998449037391 | 0.9993998449037391 | 0.9993998449037391 | 0.9993998449037391 |\n",
    "\n",
    "### Требования и запуск пайплайна\n",
    "Все запуски проводились на домашней машине с RTX3060 и ryzen 5 X3500 (?) в кондовской виртуальной среде. Для установки environment.yml требуется cuda версии 12.1. Команды для установки среды и запуска пайплайна:\n",
    "```shell\n",
    "conda env export > environment.yml\n",
    "snakemake --cores 4 --resources mem_mb=4000\n",
    "```\n",
    " ограничения на использование памяти и числа ядер необходимы, так как в пайплайне много задач и без них они моментально перегружают память и проц, и устанавливаются в зависимости от машины. \n",
    " Могу добавить, что, если ваш датасэт больше 2500 шт профилей, то shell команды в правиле train_autoencoder я бы заменила на:\n",
    " ```shell\n",
    "python -m src.models.train {output} --noise_factor {wildcards.noise} --set_size=size_of_your_set\n",
    "```\n",
    "а в правиле add_normal_noise на:\n",
    " ```shell\n",
    "python -m src.data.test_noise {input} {output} --noise {wildcards.noise} --amount_additional_profiles 1\n",
    "```\n",
    "### Структура репозитория\n",
    "------------\n",
    "\n",
    "    ├── LICENSE\n",
    "    ├── README.md          <- The top-level README for developers using this project.\n",
    "    ├── data\n",
    "    │   ├── external       <- Data from third party sources.\n",
    "    │   ├── interim        <- Intermediate data that has been transformed.\n",
    "    │   ├── processed      <- The final, canonical data sets for modeling.\n",
    "    │   └── raw            <- The original, immutable data dump.\n",
    "    │\n",
    "    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
    "    │\n",
    "    ├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "    │\n",
    "    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "    │                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "    │                         `1.0-jqp-initial-data-exploration`.\n",
    "    │\n",
    "    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "    │\n",
    "    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "    │   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "    │\n",
    "    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "    │                         generated with `pip freeze > requirements.txt`\n",
    "    │\n",
    "    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n",
    "    ├── src                <- Source code for use in this project.\n",
    "    │   ├── __init__.py    <- Makes src a Python module\n",
    "    │   │\n",
    "    │   ├── data           <- Scripts to download or generate data\n",
    "    │   │   └── make_dataset.py\n",
    "    │   │\n",
    "    │   ├── features       <- Scripts to turn raw data into features for modeling\n",
    "    │   │   └── build_features.py\n",
    "    │   │\n",
    "    │   ├── models         <- Scripts to train models and then use trained models to make\n",
    "    │   │   │                 predictions\n",
    "    │   │   ├── predict_model.py\n",
    "    │   │   └── train_model.py\n",
    "    │   │\n",
    "    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
    "    │       └── visualize.py\n",
    "    │\n",
    "    └── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "<p><small>Project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d71161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Unnamed: 0                  |   precision |   recall |   f1-score |    support |\n",
      "|:----------------------------|------------:|---------:|-----------:|-----------:|\n",
      "| Anoxybacillus_flavithermus  |    1        | 1        |   1        |   8        |\n",
      "| Bacillus_altitudinis        |    1        | 0.985075 |   0.992481 |  67        |\n",
      "| Bacillus_aryabhattai        |    1        | 1        |   1        |   4        |\n",
      "| Bacillus_atrophaeus         |    1        | 1        |   1        |  10        |\n",
      "| Bacillus_berkeleyi          |    1        | 1        |   1        |   7        |\n",
      "| Bacillus_cereus             |    1        | 1        |   1        |  46        |\n",
      "| Bacillus_chungangenis       |    1        | 1        |   1        |   5        |\n",
      "| Bacillus_clausii            |    1        | 1        |   1        |   8        |\n",
      "| Bacillus_coagulans          |    1        | 1        |   1        |   6        |\n",
      "| Bacillus_flexus             |    1        | 1        |   1        |  14        |\n",
      "| Bacillus_licheniformis      |    1        | 1        |   1        |  72        |\n",
      "| Bacillus_megaterium         |    1        | 1        |   1        |  50        |\n",
      "| Bacillus_mycoides           |    1        | 1        |   1        |   3        |\n",
      "| Bacillus_pumilus            |    0.991071 | 1        |   0.995516 | 111        |\n",
      "| Bacillus_simplex            |    1        | 1        |   1        |  40        |\n",
      "| Bacillus_subtilis           |    1        | 1        |   1        |   4        |\n",
      "| Bacillus_thuringiensis      |    1        | 1        |   1        |   5        |\n",
      "| Bacillus_weihenstephanensis |    1        | 1        |   1        |   7        |\n",
      "| E-Coli                      |    1        | 1        |   1        |   7        |\n",
      "| Geobacillus_subterraneus    |    1        | 1        |   1        |  18        |\n",
      "| accuracy                    |    0.997967 | 0.997967 |   0.997967 |   0.997967 |\n",
      "| macro avg                   |    0.999554 | 0.999254 |   0.9994   | 492        |\n",
      "| weighted avg                |    0.997986 | 0.997967 |   0.997964 | 492        |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmp = pd.read_csv(\"reports/forest_40%_group.csv\")\n",
    "tmp = tmp.to_markdown(index=False)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1f81dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Unnamed: 0   | Unnamed: 1   | Input Noise        | Input Noise.1      | Input Noise.2      | Input Noise.3      |\n",
      "|:-------------|:-------------|:-------------------|:-------------------|:-------------------|:-------------------|\n",
      "| nan          | nan          | 10%                | 20%                | 30%                | 40%                |\n",
      "| Train Noise  | 10%          | 1.0                | 1.0                | 1.0                | 1.0                |\n",
      "| Train Noise  | 20%          | 0.9982857142857142 | 0.9982857142857142 | 0.9982857142857142 | 0.9982857142857142 |\n",
      "| Train Noise  | 30%          | 0.99728002920774   | 0.99728002920774   | 0.99728002920774   | 0.99728002920774   |\n",
      "| Train Noise  | 40%          | 0.9993998449037391 | 0.9993998449037391 | 0.9993998449037391 | 0.9993998449037391 |\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.read_csv(\"reports/cross_noise_f1_group.csv\", sep=\";\")\n",
    "tmp = tmp.to_markdown(index=False)\n",
    "print(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
